CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name imdb  --template_name "Movie Expressed Sentiment 2" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/imdb/movie_expressed_sentiment_2
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name imdb  --template_name "Reviewer Opinion bad good choices" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/imdb/reviewer_opinion_bad_good_choices
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name imdb  --template_name 'Sentiment with choices ' --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/imdb/sentiment_with_choices

CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name glue --dataset_config_name qqp --template_name "quora" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/glue/qqp/quora
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name glue --dataset_config_name qqp --template_name "duplicate or not" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/glue/qqp/duplicate_or_not
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name glue --dataset_config_name qqp --template_name "same thing" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/glue/qqp/same_thing

CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name rte --template_name "MNLI crowdsource" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/rte/mnli_crowdsource
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name rte --template_name "guaranteed true" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/rte/guaranteed_true
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name rte --template_name "can we infer" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/rte/can_we_infer

CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name story_cloze --dataset_config_name 2016 --template_name "Answer Given options" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/story_cloze/2016/answer_given_options
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name story_cloze --dataset_config_name 2016 --template_name "Choose Story Ending" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/story_cloze/2016/choose_story_ending
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name story_cloze --dataset_config_name 2016 --template_name "Movie What Happens Next" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/story_cloze/2016/movie_what_happens_next

CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name winogrande --dataset_config_name winogrande_xl --template_name "does underscore refer to" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/winogrande/winogrande_xl/does_underscore_refer_to
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name winogrande --dataset_config_name winogrande_xl --template_name "stand for" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/winogrande/winogrande_xl/stand_for
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name winogrande --dataset_config_name winogrande_xl --template_name "underscore refer to" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/winogrande/winogrande_xl/underscore_refer_to

CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name wic --template_name "question-context-meaning-with-label" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/wic/question_context_meaning_with_label
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name wic --template_name "question-context-meaning" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/wic/question_context_meaning
CUDA_VISIBLE_DEVICES=0 python run_eval_instructive_negation_null.py --dataset_name super_glue --dataset_config_name wic --template_name "grammar_homework" --model_name_or_path google/t5-small-lm-adapt --checkpoint_path ../outputs/t0-small.ckpt --per_device_eval_batch_size 2 --output_dir ./debug/super_glue/wic/grammar_homework